{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d7d085-ec23-404e-8b6b-9db5e66c42b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade numpy --target ./python\n",
    "!pip install --upgrade numexpr --target ./python\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a046e3c-54b9-47fc-8fef-372f8af5849d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "SETTING = 'vision'\n",
    "dataset = load_dataset('MMMU/MMMU_Pro', SETTING, split='test')\n",
    "image = dataset[0]['image']\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496265a5-3f7b-415e-a8cd-3183ec2574eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"./python\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "from model import *\n",
    "\n",
    "#根据时间情况修改index和language值\n",
    "index =  \"wy_demo_image\"\n",
    "embedding_endpoint_name = \"cohere.embed-multilingual-v3\"\n",
    "\n",
    "embedding_type = 'bedrock' if embedding_endpoint_name.find('titan') or embedding_endpoint_name.find('cohere') else 'sagemaker'\n",
    "embeddings = init_embeddings_bedrock(embedding_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66d1e13-50b7-456a-9476-6a3a615bd13d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"./python\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "import fitz\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import base64\n",
    "from opensearch_multimodel_dataload import add_multimodel_documents\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "model_name = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    "# model_name = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "llm = init_model_bedrock(model_name)\n",
    "text_max_length = 2000\n",
    "\n",
    "prompt = \"\"\"\n",
    "brief the key search terms of the image. \n",
    "Keep the key search terms as simple as possible\n",
    "No preface, just output the key search terms directly.\n",
    "\"\"\"\n",
    "llm_max_size = 800\n",
    "display_max_size = 480\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    if i < 21:\n",
    "        continue\n",
    "    print('sleep 60 sec')\n",
    "    time.sleep(60)\n",
    "    image = dataset[i]['image']\n",
    "    image_id = dataset[i]['id']\n",
    "    answer = dataset[i]['answer']\n",
    "    subject = dataset[i]['subject']\n",
    "    \n",
    "    print(image.size)\n",
    "    if image.size[0] > llm_max_size:\n",
    "        image_for_llm = image.resize((llm_max_size,int(image.size[1]*llm_max_size / image.size[0])))\n",
    "        print('resize image size:',image_for_llm.size)\n",
    "    else:\n",
    "        image_for_llm = image\n",
    "    rgb_im = image_for_llm.convert('RGB')\n",
    "    rgb_im.save('for_llm.jpg')\n",
    "    \n",
    "    if image.size[0] > display_max_size:\n",
    "        image_for_display = image.resize((display_max_size,int(image.size[1]*display_max_size / image.size[0])))\n",
    "        print('store image size:',image_for_display.size)\n",
    "    else:\n",
    "        image_for_display = image\n",
    "    rgb_im = image_for_display.convert('RGB')\n",
    "    rgb_im.save('for_display.jpg')\n",
    "    \n",
    "    with open(\"for_llm.jpg\", \"rb\") as image_file:\n",
    "        image_bytes = image_file.read()\n",
    "        encoded_image = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "        print('for_llm len:',len(encoded_image))\n",
    "        model_kwargs = {'image': encoded_image,'max_tokens':2048,'language':'english'}\n",
    "        llm.model_kwargs = model_kwargs\n",
    "        response = llm(prompt=prompt)\n",
    "        response = response.strip()\n",
    "        texts.append(response)\n",
    "        print('response:',response)\n",
    "    \n",
    "    \n",
    "    with open(\"for_display.jpg\", \"rb\") as image_file:\n",
    "        image_bytes = image_file.read()\n",
    "        encoded_image = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "        print('for_display len:',len(encoded_image))\n",
    "        base_64_head = 'data:image/jpg;base64,'\n",
    "        image_code = base_64_head + encoded_image\n",
    "        \n",
    "    metadata = {}\n",
    "    metadata['sentence'] = response[:text_max_length] if len(response) > text_max_length else response\n",
    "    metadata['id'] = image_id\n",
    "    metadata['answer'] = answer\n",
    "    metadata['subject'] = subject\n",
    "    metadata['image_code'] = image_code\n",
    "    metadatas.append(metadata)\n",
    "    os.remove('for_llm.jpg')\n",
    "    os.remove('for_display.jpg')\n",
    "    \n",
    "    if len(texts) > 0:\n",
    "        if embedding_type == 'bedrock':\n",
    "            text_embeddings = embeddings.embed_documents([metadata['sentence'] for metadata in metadatas])\n",
    "        else:\n",
    "            text_embeddings = embeddings.embed_documents([metadata['sentence'] for metadata in metadatas],chunk_size=10)\n",
    "\n",
    "        print('texts len:',len(texts))\n",
    "        print('metadatas len:',len(metadatas))\n",
    "        print('embeddings len:',len(text_embeddings))\n",
    "        print('begin to save in vectore store')\n",
    "        add_multimodel_documents(\n",
    "            index,\n",
    "            texts=texts,\n",
    "            embeddings=text_embeddings,\n",
    "            metadatas=metadatas\n",
    "        )\n",
    "        print('finish save in vectore store:',index)\n",
    "        texts = []\n",
    "        metadatas = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99dafa-a3e1-4e0c-a420-3a0c3b130e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
