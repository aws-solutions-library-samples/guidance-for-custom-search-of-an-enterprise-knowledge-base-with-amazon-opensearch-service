{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2c8fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.25.2)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: numexpr in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.8.5)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from numexpr) (1.25.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade numpy\n",
    "!pip install --upgrade numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ef29ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host: search-smartsearch-soghr3slgoubn2356ox22gitoy.us-west-1.es.amazonaws.com\n",
      "region: us-west-1\n",
      "finish init search_qa\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import traceback\n",
    "import urllib.parse\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import time\n",
    "from smart_search_qa import SmartSearchQA\n",
    "from prompt import *\n",
    "\n",
    "\n",
    "# EMBEDDING_ENDPOINT_NAME = \"huggingface-inference-eb\"\n",
    "# EMBEDDING_ENDPOINT_NAME = \"huggingface-inference-eb-bge-zh\"\n",
    "EMBEDDING_ENDPOINT_NAME = \"huggingface-inference-eb-bge-en\"\n",
    "LLM_ENDPOINT_NAME = \"pytorch-inference-llm-v1\"\n",
    "# index =  \"smart_search_qa_test\"\n",
    "# index = \"smart_search_qa_test_0826_cn\"\n",
    "index = \"smart_search_qa_test_0826_en_3\"\n",
    "search_engine = 'opensearch'\n",
    "# language = \"chinese\"\n",
    "language = \"english\"\n",
    "\n",
    "# EMBEDDING_ENDPOINT_NAME = \"huggingface-inference-text2vec-base-chinese-v1\"\n",
    "# LLM_ENDPOINT_NAME = \"pytorch-inference-chatglm2-g5-2x\"\n",
    "# language = \"chinese\"\n",
    "# index =  \"smart_search_qa_demo_0620_cn\"\n",
    "# search_engine = 'opensearch'\n",
    "\n",
    "\n",
    "sm_client = boto3.client('secretsmanager')\n",
    "master_user = sm_client.get_secret_value(SecretId='opensearch-host-url')['SecretString']\n",
    "data= json.loads(master_user)\n",
    "es_host_name = data.get('host')\n",
    "host = es_host_name+'/' if es_host_name[-1] != '/' else es_host_name# cluster endpoint, for example: my-test-domain.us-east-1.es.amazonaws.com/\n",
    "host = host[8:-1]\n",
    "region = boto3.Session().region_name # e.g. cn-north-1\n",
    "print('host:',host)\n",
    "print('region:',region)\n",
    "\n",
    "sm_client = boto3.client('secretsmanager')\n",
    "master_user = sm_client.get_secret_value(SecretId='opensearch-master-user')['SecretString']\n",
    "data= json.loads(master_user)\n",
    "username = data.get('username')\n",
    "password = data.get('password')\n",
    "port = 443\n",
    "\n",
    "# EMBEDDING_ENDPOINT_NAME = \"pytorch-inference-all-minilm-l6-v2\"\n",
    "# LLM_ENDPOINT_NAME = \"pytorch-inference-vicuna-p3-2x\"\n",
    "# language = \"english\"\n",
    "# host =  \"bce3f35d-4471-432a-916a-d6ec42eb15a2\"\n",
    "# search_engine = 'kendra'\n",
    "# index=''\n",
    "# username=''\n",
    "# password=''\n",
    "# port=''\n",
    "# region='us-west-2'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if language == \"chinese\":\n",
    "    prompt_template = CHINESE_PROMPT_TEMPLATE\n",
    "    condense_question_prompt = CN_CONDENSE_QUESTION_PROMPT\n",
    "elif language == \"english\":\n",
    "    prompt_template = ENGLISH_PROMPT_TEMPLATE\n",
    "    condense_question_prompt = EN_CONDENSE_QUESTION_PROMPT\n",
    "\n",
    "# model_type='normal'\n",
    "model_type='bedrock'\n",
    "api_url = \"https://bx2kc13ys3.execute-api.us-east-1.amazonaws.com/prod/bedrock?\"\n",
    "    \n",
    "\n",
    "search_qa = SmartSearchQA()\n",
    "search_qa.init_cfg(index,\n",
    "                 username,\n",
    "                 password,\n",
    "                 host,\n",
    "                 port,\n",
    "                 EMBEDDING_ENDPOINT_NAME,\n",
    "                 region,\n",
    "                 LLM_ENDPOINT_NAME,\n",
    "                 temperature = 0.01,\n",
    "                 language = language,\n",
    "                 search_engine = search_engine,\n",
    "                 model_type=model_type,\n",
    "                 bedrock_api_url=api_url\n",
    "                 )\n",
    "print(\"finish init search_qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c43426ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history: []\n",
      "prompt: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "Question: Q: What is Amazon Elastic Transcoder?\n",
      "Answer: Amazon Elastic Transcoder is a highly scalable, easy to use and cost effective way for developers and businesses to convert (or “transcode”) video and audio files from their source format into versions that will playback on devices like smartphones, tablets and PCs..\n",
      "\n",
      "Question: What is Amazon Elastic Transcoder?\n",
      "Answer:\n",
      "_model_kwargs: {'modelId': 'anthropic.claude-v2', 'max_tokens': 500, 'temperature': 0.01}\n",
      "******\n",
      "bedrock prompt: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "Question: Q: What is Amazon Elastic Transcoder?\n",
      "Answer: Amazon Elastic Transcoder is a highly scalable, easy to use and cost effective way for developers and businesses to convert (or “transcode”) video and audio files from their source format into versions that will playback on devices like smartphones, tablets and PCs..\n",
      "\n",
      "Question: What is Amazon Elastic Transcoder?\n",
      "Answer:\n",
      "*******\n",
      "parameters: {'modelId': 'anthropic.claude-v2', 'max_tokens': 500, 'temperature': 0.01}\n",
      "url: https://bx2kc13ys3.execute-api.us-east-1.amazonaws.com/prod/bedrock?prompt=Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "Question: Q: What is Amazon Elastic Transcoder?\n",
      "Answer: Amazon Elastic Transcoder is a highly scalable, easy to use and cost effective way for developers and businesses to convert (or “transcode”) video and audio files from their source format into versions that will playback on devices like smartphones, tablets and PCs..\n",
      "\n",
      "Question: What is Amazon Elastic Transcoder?\n",
      "Answer:&modelId=anthropic.claude-v2&max_tokens=500&temperature=0.01\n",
      "text:  Amazon Elastic Transcoder is a cloud-based media transcoding service that allows users to easily convert video and audio files from their source format into versions that will playback on devices like smartphones, tablets and PCs. It provides features like auto-scaling, presets for popular output formats, notifications, encryption, and detailed transcoding metrics and reporting. Elastic Transcoder is fully managed, scalable and designed to be highly cost effective.\n",
      "result: {'question': 'What is Amazon Elastic Transcoder?', 'chat_history': [], 'answer': ' Amazon Elastic Transcoder is a cloud-based media transcoding service that allows users to easily convert video and audio files from their source format into versions that will playback on devices like smartphones, tablets and PCs. It provides features like auto-scaling, presets for popular output formats, notifications, encryption, and detailed transcoding metrics and reporting. Elastic Transcoder is fully managed, scalable and designed to be highly cost effective.', 'source_documents': [(Document(page_content='Question: Q: What is Amazon Elastic Transcoder?\\nAnswer: Amazon Elastic Transcoder is a highly scalable, easy to use and cost effective way for developers and businesses to convert (or “transcode”) video and audio files from their source format into versions that will playback on devices like smartphones, tablets and PCs..', metadata={'source': '/home/ec2-user/SageMaker/guidance-for-custom-search-of-an-enterprise-knowledge-base-on-aws/docs/english_docs/aws_faq__en_Elastic_Transcoder_faqs_ .csv', 'row': 0}), 0.018686099, 'Question: Q: What is Amazon Elastic Transcoder?\\nAnswer: Amazon Elastic Transcoder is a highly scalable, easy to use and cost effective way for developers and businesses to convert (or “transcode”) video and audio files from their source format into versions that will playback on devices like smartphones, tablets and PCs.')], 'generated_question': 'What is Amazon Elastic Transcoder?'}\n",
      "--------------------\n",
      "answer: Amazon Elastic Transcoder is a cloud-based media transcoding service that allows users to easily convert video and audio files from their source format into versions that will playback on devices like smartphones, tablets and PCs. It provides features like auto-scaling, presets for popular output formats, notifications, encryption, and detailed transcoding metrics and reporting. Elastic Transcoder is fully managed, scalable and designed to be highly cost effective.\n"
     ]
    }
   ],
   "source": [
    "# query='什么是Amazon SageMaker？'\n",
    "# query='怎么部署呢？'\n",
    "# query='what is aws s3?'\n",
    "# query= '今天天气怎么样？'\n",
    "# query= '美国有多少个州？'\n",
    "\n",
    "# query='亚马逊云科技中国区域运营模式有什么特点？'\n",
    "# query='亚马逊云科技有媒体行业解决方案吗？'\n",
    "# query=\"游戏行业呢？\"\n",
    "# query='零售行业呢？'\n",
    "\n",
    "query='What is Amazon Elastic Transcoder?'\n",
    "\n",
    "top_k = 1\n",
    "session_id='bedrock35'\n",
    "table_name='LambdaStack-ChatSessionRecord189120C3-1HYZ55TUDXEUM'\n",
    "\n",
    "\n",
    "result = search_qa.get_answer_from_conversational(query,\n",
    "                            session_id,\n",
    "                            table_name,\n",
    "                            language,\n",
    "                            prompt_template=prompt_template,\n",
    "                            condense_question_prompt=condense_question_prompt,\n",
    "                            top_k=top_k\n",
    "                            )    \n",
    "print('result:',result)\n",
    "print('--------------------')\n",
    "# print('answer:',result['answer'])\n",
    "answer=result['answer'].split('\\n\\nhuman')[0].split('\\n\\n用户')[0].split('\\n\\nquestion')[0].split('\\n\\nQuestion')[0].strip()\n",
    "print('answer:',answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7f0721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_documents = result['source_documents']\n",
    "if search_engine == \"opensearch\":\n",
    "    source_docs = [doc[0] for doc in source_documents]\n",
    "    query_doc_scores = [doc[1] for doc in source_documents]\n",
    "    sentences = [doc[2] for doc in source_documents]\n",
    "elif search_engine == \"kendra\":\n",
    "    source_docs = source_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52ea8915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer:  AWS S3 is a fully managed object storage service provided by Amazon Web Services (AWS). It stands for Simple Storage Service and is designed to provide developers and IT teams with a scalable and high-performance way to store and retrieve data. AWS S3 is used by millions of customers worldwide and is the most widely used object storage service in the world.\n",
      "query: what is aws s3?\n",
      "1.qa_relate_score: 0.8680334150733228\n"
     ]
    }
   ],
   "source": [
    "answer = result['answer']        \n",
    "\n",
    "if language == \"english\":\n",
    "    answer = answer.split('Answer:')[-1]\n",
    "print('answer:',answer)\n",
    "print('query:',query)\n",
    "#cal qa_relate_score\n",
    "qa_relate_score = search_qa.get_qa_relation_score(query,answer)\n",
    "print('1.qa_relate_score:',qa_relate_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e544ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.answer_relate_scores: [0.6697910927220708, 0.5876096499497694, 0.6455764957531428]\n"
     ]
    }
   ],
   "source": [
    "answer_relate_scores = []\n",
    "cal_answer = answer\n",
    "if language == \"chinese\" and len(answer) > 150:\n",
    "    cal_answer = answer[:150]\n",
    "    \n",
    "for source_doc in source_docs:\n",
    "    cal_source_page_content = source_doc.page_content\n",
    "    if language == \"chinese\" and len(cal_source_page_content) > 150:\n",
    "        cal_source_page_content = cal_source_page_content[:150]\n",
    "    answer_relate_score = search_qa.get_qa_relation_score(cal_answer,cal_source_page_content)\n",
    "    answer_relate_scores.append(answer_relate_score)\n",
    "print('2.answer_relate_scores:',answer_relate_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "155ae8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_relate_docs: [Document(page_content='Document Title: What is Amazon S3? - Amazon Simple Storage Service \\nDocument Excerpt: \\nIt is designed to make web-scale computing easier for developers. Amazon S3 has a simple web services interface that you can use to store and retrieve any amount of data, at any time, from anywhere on the web. It gives any developer access to the same highly scalable, reliable, fast, inexpensive data storage infrastructure that Amazon uses to run its own global network of web sites. The service aims to maximize benefits of scale and to pass those benefits on to developers. This guide explains the core concepts of Amazon S3, such as buckets, access points, and objects, and how to work with these resources using the Amazon S3 application programming interface (API). How do I? Information Relevant sections General product overview and pricing Amazon S3 Get a quick hands-on introduction to Amazon S3 Amazon Simple Storage Service Getting Started Guide Learn about Amazon S3 key terminology and concepts Introduction to Amazon S3 How do I work with buckets?\\n', metadata={'source': 'http://docs.aws.amazon.com/AmazonS3/latest/dev/Welcome.html', 'title': 'What is Amazon S3? - Amazon Simple Storage Service', 'excerpt': 'It is designed to make web-scale computing easier for developers. Amazon S3 has a simple web services interface that you can use to store and retrieve any amount of data, at any time, from anywhere on the web. It gives any developer access to the same highly scalable, reliable, fast, inexpensive data storage infrastructure that Amazon uses to run its own global network of web sites. The service aims to maximize benefits of scale and to pass those benefits on to developers. This guide explains the core concepts of Amazon S3, such as buckets, access points, and objects, and how to work with these resources using the Amazon S3 application programming interface (API). How do I? Information Relevant sections General product overview and pricing Amazon S3 Get a quick hands-on introduction to Amazon S3 Amazon Simple Storage Service Getting Started Guide Learn about Amazon S3 key terminology and concepts Introduction to Amazon S3 How do I work with buckets?'}), Document(page_content='Document Title: Amazon Simple Storage Service (Amazon S3) - Amazon Elastic Compute Cloud \\nDocument Excerpt: \\nIt is designed to make web-scale computing easier by enabling you to store and retrieve any amount of data, at any time, from within Amazon EC2 or anywhere on the web. Amazon S3 stores data objects redundantly on multiple devices across multiple facilities and allows concurrent read or write access to these data objects by many separate clients or application threads. You can use the redundant data stored in Amazon S3 to recover quickly and reliably from instance or application failures. Amazon EC2 uses Amazon S3 for storing Amazon Machine Images (AMIs). You use AMIs for launching EC2 instances. In case of instance failure, you can use the stored AMI to immediately launch another instance, thereby allowing for fast recovery and business continuity. Amazon EC2 also uses Amazon S3 to store snapshots (backup copies) of the data volumes. You can use snapshots for recovering data quickly and reliably in case of application or system failures.\\n', metadata={'source': 'http://docs.aws.amazon.com/AWSEC2/latest/WindowsGuide/AmazonS3.html', 'title': 'Amazon Simple Storage Service (Amazon S3) - Amazon Elastic Compute Cloud', 'excerpt': 'It is designed to make web-scale computing easier by enabling you to store and retrieve any amount of data, at any time, from within Amazon EC2 or anywhere on the web. Amazon S3 stores data objects redundantly on multiple devices across multiple facilities and allows concurrent read or write access to these data objects by many separate clients or application threads. You can use the redundant data stored in Amazon S3 to recover quickly and reliably from instance or application failures. Amazon EC2 uses Amazon S3 for storing Amazon Machine Images (AMIs). You use AMIs for launching EC2 instances. In case of instance failure, you can use the stored AMI to immediately launch another instance, thereby allowing for fast recovery and business continuity. Amazon EC2 also uses Amazon S3 to store snapshots (backup copies) of the data volumes. You can use snapshots for recovering data quickly and reliably in case of application or system failures.'}), Document(page_content='Document Title: Amazon Simple Storage Service (Amazon S3) - Amazon Elastic Compute Cloud \\nDocument Excerpt: \\nIt is designed to make web-scale computing easier by enabling you to store and retrieve any amount of data, at any time, from within Amazon EC2 or anywhere on the web. Amazon S3 stores data objects redundantly on multiple devices across multiple facilities and allows concurrent read or write access to these data objects by many separate clients or application threads. You can use the redundant data stored in Amazon S3 to recover quickly and reliably from instance or application failures. Amazon EC2 uses Amazon S3 for storing Amazon Machine Images (AMIs). You use AMIs for launching EC2 instances. In case of instance failure, you can use the stored AMI to immediately launch another instance, thereby allowing for fast recovery and business continuity. Amazon EC2 also uses Amazon S3 to store snapshots (backup copies) of the data volumes. You can use snapshots for recovering data quickly and reliably in case of application or system failures.\\n', metadata={'source': 'http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonS3.html', 'title': 'Amazon Simple Storage Service (Amazon S3) - Amazon Elastic Compute Cloud', 'excerpt': 'It is designed to make web-scale computing easier by enabling you to store and retrieve any amount of data, at any time, from within Amazon EC2 or anywhere on the web. Amazon S3 stores data objects redundantly on multiple devices across multiple facilities and allows concurrent read or write access to these data objects by many separate clients or application threads. You can use the redundant data stored in Amazon S3 to recover quickly and reliably from instance or application failures. Amazon EC2 uses Amazon S3 for storing Amazon Machine Images (AMIs). You use AMIs for launching EC2 instances. In case of instance failure, you can use the stored AMI to immediately launch another instance, thereby allowing for fast recovery and business continuity. Amazon EC2 also uses Amazon S3 to store snapshots (backup copies) of the data volumes. You can use snapshots for recovering data quickly and reliably in case of application or system failures.'})]\n",
      "find_index: []\n",
      "3.list_overlap_score: 0.0\n"
     ]
    }
   ],
   "source": [
    "#cal answer_relate_scores\n",
    "find_answer_top_k = 3\n",
    "answer_relate_docs = search_qa.get_retriever(find_answer_top_k).get_relevant_documents(answer)\n",
    "print('answer_relate_docs:',answer_relate_docs)\n",
    "if search_engine == \"opensearch\":\n",
    "    answer_relate_docs = [doc[0] for doc in answer_relate_docs]\n",
    "\n",
    "find_index = []\n",
    "for answer_relate_doc in answer_relate_docs:\n",
    "    try:\n",
    "        relate_source = answer_relate_doc.metadata['source']\n",
    "        relate_page_content = answer_relate_doc.page_content\n",
    "    except KeyError:\n",
    "        print(\"KeyError found\")\n",
    "        continue\n",
    "    for i in range(len(source_docs)):\n",
    "        source_page_content = source_docs[i].page_content\n",
    "        if source_page_content == relate_page_content:\n",
    "            find_index.append(i)\n",
    "            break\n",
    "print('find_index:',find_index)\n",
    "\n",
    "if len(find_index) > 0:                \n",
    "    list_score = 0\n",
    "    find_topk = 1\n",
    "    query_relate_docs_len = len(source_docs)\n",
    "    answer_relate_docs_len = len(answer_relate_docs)\n",
    "    for i in range(query_relate_docs_len):\n",
    "        for j in range(len(find_index)):\n",
    "            if i == find_index[j]:\n",
    "                list_score += (query_relate_docs_len-i)*(answer_relate_docs_len-j)        \n",
    "    print('qa_list_score:',list_score)\n",
    "\n",
    "    total = query_relate_docs_len*answer_relate_docs_len\n",
    "    if query_relate_docs_len > 1 and answer_relate_docs_len > 1:\n",
    "        total += (query_relate_docs_len-1)*(answer_relate_docs_len-1)\n",
    "    print('total score:',total)\n",
    "\n",
    "    list_overlap_score = round(list_score/total,3)\n",
    "else:\n",
    "    list_overlap_score = 0.0\n",
    "print('3.list_overlap_score:',list_overlap_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c0a6682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 0, 'source': 'cloudtrail-logging.html', 'paragraph': \"Document Title: Logging Amazon S3 API calls using AWS CloudTrail - Amazon Simple Storage Service Document Excerpt: AWSDocumentationAmazon Simple Storage Service (S3)Developer Guide Amazon S3 information in CloudTrailUsing CloudTrail logs with Amazon S3 server access logs and CloudWatch LogsExample: Amazon S3 log file entriesRelated resources Logging Amazon S3 API calls using AWS CloudTrail Amazon S3 is integrated with AWS CloudTrail, a service that provides a record of actions taken by a user, role, or an AWS service in Amazon S3. CloudTrail captures a subset of API calls for Amazon S3 as events, including calls from the Amazon S3 console and from code calls to the Amazon S3 APIs. API calls using AWS CloudTrail If you create a trail, you can enable continuous delivery of CloudTrail events to an Amazon S3 bucket, including events for Amazon S3. If you don't configure a trail, you can still view the most recent events in the CloudTrail console in Event history.\", 'sentence': \"Document Title: Logging Amazon S3 API calls using AWS CloudTrail - Amazon Simple Storage Service Document Excerpt: AWSDocumentationAmazon Simple Storage Service (S3)Developer Guide Amazon S3 information in CloudTrailUsing CloudTrail logs with Amazon S3 server access logs and CloudWatch LogsExample: Amazon S3 log file entriesRelated resources Logging Amazon S3 API calls using AWS CloudTrail Amazon S3 is integrated with AWS CloudTrail, a service that provides a record of actions taken by a user, role, or an AWS service in Amazon S3. CloudTrail captures a subset of API calls for Amazon S3 as events, including calls from the Amazon S3 console and from code calls to the Amazon S3 APIs. API calls using AWS CloudTrail If you create a trail, you can enable continuous delivery of CloudTrail events to an Amazon S3 bucket, including events for Amazon S3. If you don't configure a trail, you can still view the most recent events in the CloudTrail console in Event history.\", 'score': 0}, {'id': 1, 'source': 'cloudtrail-logging.html', 'paragraph': \"Document Title: Logging Amazon S3 API calls using AWS CloudTrail - Amazon Simple Storage Service Document Excerpt: API calls using AWS CloudTrail Amazon S3 is integrated with AWS CloudTrail, a service that provides a record of actions taken by a user, role, or an AWS service in Amazon S3. CloudTrail captures a subset of API calls for Amazon S3 as events, including calls from the Amazon S3 console and from code calls to the Amazon S3 APIs. If you create a trail, you can enable continuous delivery of CloudTrail events to an Amazon S3 bucket, including events for Amazon S3. If you don't configure a trail, you can still view the most recent events in the CloudTrail console in Event history. Using the information collected by CloudTrail, you can determine the request that was made to Amazon S3, the IP address from which the request was made, who made the request, when it was made, and additional details. To learn more about CloudTrail, including how to configure and enable it, see the AWS CloudTrail User Guide.\", 'sentence': \"Document Title: Logging Amazon S3 API calls using AWS CloudTrail - Amazon Simple Storage Service Document Excerpt: API calls using AWS CloudTrail Amazon S3 is integrated with AWS CloudTrail, a service that provides a record of actions taken by a user, role, or an AWS service in Amazon S3. CloudTrail captures a subset of API calls for Amazon S3 as events, including calls from the Amazon S3 console and from code calls to the Amazon S3 APIs. If you create a trail, you can enable continuous delivery of CloudTrail events to an Amazon S3 bucket, including events for Amazon S3. If you don't configure a trail, you can still view the most recent events in the CloudTrail console in Event history. Using the information collected by CloudTrail, you can determine the request that was made to Amazon S3, the IP address from which the request was made, who made the request, when it was made, and additional details. To learn more about CloudTrail, including how to configure and enable it, see the AWS CloudTrail User Guide.\", 'score': 0}, {'id': 2, 'source': 'BucketBilling.html', 'paragraph': \"Document Title: Billing and usage reporting for S3 buckets - Amazon Simple Storage Service Document Excerpt: AWS always bills the owner of the S3 bucket for Amazon S3 fees, unless the bucket was created as a Requester Pays bucket. For more information about Requester Pays, see Requester Pays buckets. For more information about billing reports, see AWS Billing reports for Amazon S3. Usage report – A summary of activity for a specific service, aggregated by hour, day, or month. You can choose which usage type and operation to include. You can also choose how the data is aggregated. For more information, see AWS usage report for Amazon S3. The following topics provide information about billing and usage reporting for Amazon S3. Topics AWS Billing reports for Amazon S3 AWS usage report for Amazon S3 Understanding your AWS billing and usage reports for Amazon S3 Using cost allocation S3 bucket tags Javascript is disabled or is unavailable in your browser. To use the AWS Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions. Document Conventions Access Control Billing reports Did this page help you? - Yes Thanks for letting us know we're doing a good job!\", 'sentence': \"Document Title: Billing and usage reporting for S3 buckets - Amazon Simple Storage Service Document Excerpt: AWS always bills the owner of the S3 bucket for Amazon S3 fees, unless the bucket was created as a Requester Pays bucket. For more information about Requester Pays, see Requester Pays buckets. For more information about billing reports, see AWS Billing reports for Amazon S3. Usage report – A summary of activity for a specific service, aggregated by hour, day, or month. You can choose which usage type and operation to include. You can also choose how the data is aggregated. For more information, see AWS usage report for Amazon S3. The following topics provide information about billing and usage reporting for Amazon S3. Topics AWS Billing reports for Amazon S3 AWS usage report for Amazon S3 Understanding your AWS billing and usage reports for Amazon S3 Using cost allocation S3 bucket tags Javascript is disabled or is unavailable in your browser. To use the AWS Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions. Document Conventions Access Control Billing reports Did this page help you? - Yes Thanks for letting us know we're doing a good job!\", 'score': 0}]\n"
     ]
    }
   ],
   "source": [
    "source_list = []\n",
    "for i in range(len(source_docs)):\n",
    "    source = {}\n",
    "    source[\"id\"] = i\n",
    "    try:\n",
    "        source[\"source\"] = os.path.split(source_docs[i].metadata['source'])[-1]\n",
    "    except KeyError:\n",
    "        print(\"KeyError found\")                    \n",
    "    source[\"paragraph\"] =source_docs[i].page_content.replace(\"\\n\",\"\")\n",
    "    source[\"sentence\"] = sentences[i] if search_engine == \"opensearch\" else source_docs[i].page_content.replace(\"\\n\",\"\")\n",
    "    source[\"score\"] = query_doc_scores[i] if search_engine == \"opensearch\" else 1\n",
    "    source_list.append(source)\n",
    "print(source_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06353ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 0, '_score': 1, 'title': 'cloudtrail-logging.html', 'sentence': \"Document Title: Logging Amazon S3 API calls using AWS CloudTrail - Amazon Simple Storage Service Document Excerpt: AWSDocumentationAmazon Simple Storage Service (S3)Developer Guide Amazon S3 information in CloudTrailUsing CloudTrail logs with Amazon S3 server access logs and CloudWatch LogsExample: Amazon S3 log file entriesRelated resources Logging Amazon S3 API calls using AWS CloudTrail Amazon S3 is integrated with AWS CloudTrail, a service that provides a record of actions taken by a user, role, or an AWS service in Amazon S3. CloudTrail captures a subset of API calls for Amazon S3 as events, including calls from the Amazon S3 console and from code calls to the Amazon S3 APIs. API calls using AWS CloudTrail If you create a trail, you can enable continuous delivery of CloudTrail events to an Amazon S3 bucket, including events for Amazon S3. If you don't configure a trail, you can still view the most recent events in the CloudTrail console in Event history.\", 'paragraph': \"Document Title: Logging Amazon S3 API calls using AWS CloudTrail - Amazon Simple Storage Service Document Excerpt: AWSDocumentationAmazon Simple Storage Service (S3)Developer Guide Amazon S3 information in CloudTrailUsing CloudTrail logs with Amazon S3 server access logs and CloudWatch LogsExample: Amazon S3 log file entriesRelated resources Logging Amazon S3 API calls using AWS CloudTrail Amazon S3 is integrated with AWS CloudTrail, a service that provides a record of actions taken by a user, role, or an AWS service in Amazon S3. CloudTrail captures a subset of API calls for Amazon S3 as events, including calls from the Amazon S3 console and from code calls to the Amazon S3 APIs. API calls using AWS CloudTrail If you create a trail, you can enable continuous delivery of CloudTrail events to an Amazon S3 bucket, including events for Amazon S3. If you don't configure a trail, you can still view the most recent events in the CloudTrail console in Event history.\", 'sentence_id': 0, 'paragraph_id': 0}, {'_id': 1, '_score': 1, 'title': 'cloudtrail-logging.html', 'sentence': \"Document Title: Logging Amazon S3 API calls using AWS CloudTrail - Amazon Simple Storage Service Document Excerpt: API calls using AWS CloudTrail Amazon S3 is integrated with AWS CloudTrail, a service that provides a record of actions taken by a user, role, or an AWS service in Amazon S3. CloudTrail captures a subset of API calls for Amazon S3 as events, including calls from the Amazon S3 console and from code calls to the Amazon S3 APIs. If you create a trail, you can enable continuous delivery of CloudTrail events to an Amazon S3 bucket, including events for Amazon S3. If you don't configure a trail, you can still view the most recent events in the CloudTrail console in Event history. Using the information collected by CloudTrail, you can determine the request that was made to Amazon S3, the IP address from which the request was made, who made the request, when it was made, and additional details. To learn more about CloudTrail, including how to configure and enable it, see the AWS CloudTrail User Guide.\", 'paragraph': \"Document Title: Logging Amazon S3 API calls using AWS CloudTrail - Amazon Simple Storage Service Document Excerpt: API calls using AWS CloudTrail Amazon S3 is integrated with AWS CloudTrail, a service that provides a record of actions taken by a user, role, or an AWS service in Amazon S3. CloudTrail captures a subset of API calls for Amazon S3 as events, including calls from the Amazon S3 console and from code calls to the Amazon S3 APIs. If you create a trail, you can enable continuous delivery of CloudTrail events to an Amazon S3 bucket, including events for Amazon S3. If you don't configure a trail, you can still view the most recent events in the CloudTrail console in Event history. Using the information collected by CloudTrail, you can determine the request that was made to Amazon S3, the IP address from which the request was made, who made the request, when it was made, and additional details. To learn more about CloudTrail, including how to configure and enable it, see the AWS CloudTrail User Guide.\", 'sentence_id': 1, 'paragraph_id': 1}, {'_id': 2, '_score': 1, 'title': 'BucketBilling.html', 'sentence': \"Document Title: Billing and usage reporting for S3 buckets - Amazon Simple Storage Service Document Excerpt: AWS always bills the owner of the S3 bucket for Amazon S3 fees, unless the bucket was created as a Requester Pays bucket. For more information about Requester Pays, see Requester Pays buckets. For more information about billing reports, see AWS Billing reports for Amazon S3. Usage report – A summary of activity for a specific service, aggregated by hour, day, or month. You can choose which usage type and operation to include. You can also choose how the data is aggregated. For more information, see AWS usage report for Amazon S3. The following topics provide information about billing and usage reporting for Amazon S3. Topics AWS Billing reports for Amazon S3 AWS usage report for Amazon S3 Understanding your AWS billing and usage reports for Amazon S3 Using cost allocation S3 bucket tags Javascript is disabled or is unavailable in your browser. To use the AWS Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions. Document Conventions Access Control Billing reports Did this page help you? - Yes Thanks for letting us know we're doing a good job!\", 'paragraph': \"Document Title: Billing and usage reporting for S3 buckets - Amazon Simple Storage Service Document Excerpt: AWS always bills the owner of the S3 bucket for Amazon S3 fees, unless the bucket was created as a Requester Pays bucket. For more information about Requester Pays, see Requester Pays buckets. For more information about billing reports, see AWS Billing reports for Amazon S3. Usage report – A summary of activity for a specific service, aggregated by hour, day, or month. You can choose which usage type and operation to include. You can also choose how the data is aggregated. For more information, see AWS usage report for Amazon S3. The following topics provide information about billing and usage reporting for Amazon S3. Topics AWS Billing reports for Amazon S3 AWS usage report for Amazon S3 Understanding your AWS billing and usage reports for Amazon S3 Using cost allocation S3 bucket tags Javascript is disabled or is unavailable in your browser. To use the AWS Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions. Document Conventions Access Control Billing reports Did this page help you? - Yes Thanks for letting us know we're doing a good job!\", 'sentence_id': 2, 'paragraph_id': 2}]\n"
     ]
    }
   ],
   "source": [
    "source_list = []\n",
    "for i in range(len(source_docs)):\n",
    "    source = {}\n",
    "    source[\"_id\"] = i\n",
    "    source[\"_score\"] = query_doc_scores[i] if search_engine == \"opensearch\" else 1\n",
    "    source[\"title\"] = os.path.split(source_docs[i].metadata['source'])[-1]\n",
    "    source[\"sentence\"] = sentences[i] if search_engine == \"opensearch\" else source_docs[i].page_content.replace(\"\\n\",\"\")\n",
    "    source[\"paragraph\"] =source_docs[i].page_content.replace(\"\\n\",\"\")\n",
    "    source[\"sentence_id\"] = i\n",
    "    if 'row' in source_docs[i].metadata.keys():\n",
    "        source[\"paragraph_id\"] = source_docs[i].metadata['row']\n",
    "    elif 'page' in source_docs[i].metadata.keys():\n",
    "        source[\"paragraph_id\"] = source_docs[i].metadata['page']\n",
    "    else:\n",
    "        source[\"paragraph_id\"] = i\n",
    "    source_list.append(source)\n",
    "print(source_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f823d1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
